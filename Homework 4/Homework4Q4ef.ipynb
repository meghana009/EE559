{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM44rqjfWkr4V41ehOUXkoc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"UvqpYZDu2H8b","executionInfo":{"status":"ok","timestamp":1677282954428,"user_tz":480,"elapsed":947,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","from sklearn.utils import shuffle"]},{"cell_type":"code","source":["def data_split(x,y):\n","  xn_train = x[:,:-1]\n","  xn_label = x[:,-1]\n","  xn_test = y[:,:-1]\n","  yn_label = y[:,-1]\n","  return xn_train, xn_label, xn_test, yn_label"],"metadata":{"id":"omGyA0Lr2J3R","executionInfo":{"status":"ok","timestamp":1677282954429,"user_tz":480,"elapsed":5,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def ref(x,y):\n","  z = np.zeros([y.shape[0],1])\n","  for i in range(y.shape[0]):\n","    if y[i] == 1:\n","      z[i] = 1\n","    else:\n","      z[i] = -1\n","  #xn = np.column_stack((np.ones([x.shape[0],1],dtype=float),x))\n","  g = np.multiply(x, z)\n","  return x, g \n","\n","def crit(w,x):\n","  j = 0\n","  l = int(x.shape[0])\n","  for i in range(l):\n","    if (np.dot(w.T, x[i,:]) <= 0):\n","      j = (j - np.dot(w.T, x[i,:]))\n","  return j\n","\n","def predict(w,x):\n","  w_pred = np.zeros([int(x.shape[0]),1])\n","  for i in range(int(x.shape[0])):\n","    z = np.dot(w.T, x[i,:])\n","    if z < 0:\n","      w_pred[i] = 2\n","    else:\n","      w_pred[i] = 1\n","  \n","  return w_pred\n","\n","def error(x,y):\n","  count = 0\n","  for i in range(int(x.shape[0])):\n","    if x[i]!=y[i]:\n","      count = count + 1\n","  err = (count/int(x.shape[0]))*100\n","  return err"],"metadata":{"id":"l-8eS3AG2Lao","executionInfo":{"status":"ok","timestamp":1677282955304,"user_tz":480,"elapsed":3,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_train = np.array(np.loadtxt(\"/content/dataset1_train.csv\", delimiter = \",\", dtype = float))\n","data_test = np.array(np.loadtxt(\"/content/dataset1_test.csv\", delimiter = \",\", dtype = float))"],"metadata":{"id":"rZiAHeRJ2NdX","executionInfo":{"status":"ok","timestamp":1677283125638,"user_tz":480,"elapsed":237,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["xn_train,xn_label,xn_test,y_label = data_split(data_train, data_test)"],"metadata":{"id":"-XinpeJr2PCX","executionInfo":{"status":"ok","timestamp":1677283126596,"user_tz":480,"elapsed":5,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["xn1 = np.column_stack((np.ones([xn_train.shape[0],1],dtype=float),xn_train))\n","n_features = xn1.shape[1]\n","X3 = np.zeros((xn1.shape[0], n_features * (n_features + 1) * (n_features + 2) // 6))\n","k = 0\n","for i in range(n_features):\n","    X3[:, k] = xn1[:, i] ** 3  # cubic term\n","    k += 1\n","    for j in range(i + 1, n_features):\n","        X3[:, k] = xn1[:, i] ** 2 * xn1[:, j]  # squared and linear interaction term\n","        k += 1\n","        X3[:, k] = xn1[:, i] * xn1[:, j] ** 2  # linear and squared interaction term\n","        k += 1\n","        for l in range(j + 1, n_features):\n","            X3[:, k] = xn1[:, i] * xn1[:, j] * xn1[:, l]  # triple interaction term\n","            k += 1\n","\n","# Combine the original and new features\n","x_new = np.hstack((xn1, X3))\n","\n","xn, g = ref(x_new,xn_label)"],"metadata":{"id":"XknbvLIV2aTC","executionInfo":{"status":"ok","timestamp":1677283126995,"user_tz":480,"elapsed":5,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#Testing Dataset\n","test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","n_features = test_xn.shape[1]\n","X3 = np.zeros((test_xn.shape[0], n_features * (n_features + 1) * (n_features + 2) // 6))\n","k = 0\n","for i in range(n_features):\n","    X3[:, k] = test_xn[:, i] ** 3  # cubic term\n","    k += 1\n","    for j in range(i + 1, n_features):\n","        X3[:, k] = test_xn[:, i] ** 2 * test_xn[:, j]  # squared and linear interaction term\n","        k += 1\n","        X3[:, k] = test_xn[:, i] * test_xn[:, j] ** 2  # linear and squared interaction term\n","        k += 1\n","        for l in range(j + 1, n_features):\n","            X3[:, k] = test_xn[:, i] * test_xn[:, j] * test_xn[:, l]  # triple interaction term\n","            k += 1\n","\n","# Combine the original and new features\n","y_new = np.hstack((test_xn, X3))"],"metadata":{"id":"-xK59d-Q2vEe","executionInfo":{"status":"ok","timestamp":1677283126996,"user_tz":480,"elapsed":5,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["w = np.ones([13,1])\n","w_out = np.ones([13,10000])\n","\n","#Training \n","l = int(g.shape[0])\n","epochs = int(10000/l)\n","axis = []\n","\n","\n","\n","for i in range(epochs):\n","  count = 0\n","  xn,g,xn_label = shuffle(xn,g,xn_label)\n","  # g = shuffle(g)\n","  # xn_label = shuffle(xn_label)\n","\n","  for j in range(l):\n","    ind = i*epochs + j\n","    axis.append(ind + 1)\n","    z = np.dot(w.T, g[j,:])\n","\n","    if z <= 0:\n","      w = w + 1*g[j,:].reshape([13,1])\n","      count = 0\n","    \n","    else:\n","      count = count + 1\n","    \n","    w_out[:,ind] = w.T\n","  \n","  if count == 100:\n","    print('Linearly Separable')\n","    break\n","\n","J_d = np.zeros(10000)\n","\n","for j in range(10000):\n","  J_d[j] = crit(w_out[:,j], g)\n","\n","w_opt = w_out[:, np.argmin(J_d)]\n","print('The optimal weights are:', w_opt)\n","\n","train_label = predict(w_opt,xn)\n","print('The training classification error is:', error(train_label, xn_label))\n","\n","#test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","test_label = predict(w_opt,y_new)\n","\n","print('The testing classification error is:', error(test_label, y_label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kth76-l93Me_","executionInfo":{"status":"ok","timestamp":1677283131898,"user_tz":480,"elapsed":3964,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}},"outputId":"d56e2468-4ca5-44a4-a93f-e628a3fea6b8"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Linearly Separable\n","The optimal weights are: [ -1.          -4.22976897   3.86739868  -1.          -4.22976897\n","  -2.27730762  -1.13918358   3.86739868  -2.28280219 -18.31385054\n","  -5.65262561   5.59748815  23.08129263]\n","The training classification error is: 0.0\n","The testing classification error is: 0.0\n"]}]},{"cell_type":"code","source":["w = np.ones([13,1])\n","w_out = np.ones([13,10000])\n","\n","#Training \n","l = int(g.shape[0])\n","epochs = int(10000/l)\n","axis = []\n","accu_train = []\n","accu_test = []\n","k = 0\n","w_t = []\n","\n","while (k!=10):\n","  for i in range(epochs):\n","    count = 0\n","    xn,g,xn_label = shuffle(xn,g,xn_label)\n","    # g = shuffle(g)\n","    # xn_label = shuffle(xn_label)\n","\n","    for j in range(l):\n","      ind = i*epochs + j\n","      axis.append(ind + 1)\n","      z = np.dot(w.T, g[j,:])\n","\n","      if z <= 0:\n","        w = w + 1*g[j,:].reshape([13,1])\n","        count = 0\n","      \n","      else:\n","        count = count + 1\n","      \n","      w_out[:,ind] = w.T\n","    \n","    if count == 100:\n","      #print('Linearly Separable')\n","      break\n","\n","  J_d = np.zeros(10000)\n","\n","  for j in range(10000):\n","    J_d[j] = crit(w_out[:,j], g)\n","\n","  w_opt = w_out[:, np.argmin(J_d)]\n","  #print('The optimal weights are:', w_opt)\n","  w_t.append(w_opt)\n","\n","  train_label = predict(w_opt,xn)\n","  err = error(train_label, xn_label)\n","  accu_train.append(100 - err)\n","  #print('The training classification error is:', error(train_label, xn_label))\n","\n","  #test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","  test_label = predict(w_opt,y_new)\n","  err_test = error(test_label, y_label)\n","  accu_test.append(100 - err_test)\n","  k = k + 1\n","  #print('The testing classification error is:', error(test_label, y_label))\n","\n","mean_train = np.mean(np.array(accu_train), axis = 0)\n","std_train = np.std(np.array(accu_train), axis = 0)\n","mean_test = np.mean(np.array(accu_test), axis = 0)\n","std_test = np.std(np.array(accu_test), axis = 0)\n","\n","print(\"The mean and standard deviation for training accuracy is as follows: {:.2f}%, {:.2f}\".format(mean_train,std_train))\n","print(\"The mean and standard deviation for testing accuracy is as follows: {:.2f}%, {:.2f}\".format(mean_test,std_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8Yoayil3Rvk","executionInfo":{"status":"ok","timestamp":1677283198699,"user_tz":480,"elapsed":30433,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}},"outputId":"8e282417-2205-4fdd-a83f-1f0564e19d79"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["The mean and standard deviation for training accuracy is as follows: 100.00%, 0.00\n","The mean and standard deviation for testing accuracy is as follows: 100.00%, 0.00\n"]}]},{"cell_type":"code","source":["data_train = np.array(np.loadtxt(\"/content/dataset2_train.csv\", delimiter = \",\", dtype = float))\n","data_test = np.array(np.loadtxt(\"/content/dataset2_test.csv\", delimiter = \",\", dtype = float))\n","\n","xn_train,xn_label,xn_test,y_label = data_split(data_train, data_test)\n","\n","\n","xn1 = np.column_stack((np.ones([xn_train.shape[0],1],dtype=float),xn_train))\n","n_features = xn1.shape[1]\n","X3 = np.zeros((xn1.shape[0], n_features * (n_features + 1) * (n_features + 2) // 6))\n","k = 0\n","for i in range(n_features):\n","    X3[:, k] = xn1[:, i] ** 3  # cubic term\n","    k += 1\n","    for j in range(i + 1, n_features):\n","        X3[:, k] = xn1[:, i] ** 2 * xn1[:, j]  # squared and linear interaction term\n","        k += 1\n","        X3[:, k] = xn1[:, i] * xn1[:, j] ** 2  # linear and squared interaction term\n","        k += 1\n","        for l in range(j + 1, n_features):\n","            X3[:, k] = xn1[:, i] * xn1[:, j] * xn1[:, l]  # triple interaction term\n","            k += 1\n","\n","# Combine the original and new features\n","x_new = np.hstack((xn1, X3))\n","\n","xn, g = ref(x_new,xn_label)\n","\n","#Testing Dataset\n","test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","n_features = test_xn.shape[1]\n","X3 = np.zeros((test_xn.shape[0], n_features * (n_features + 1) * (n_features + 2) // 6))\n","k = 0\n","for i in range(n_features):\n","    X3[:, k] = test_xn[:, i] ** 3  # cubic term\n","    k += 1\n","    for j in range(i + 1, n_features):\n","        X3[:, k] = test_xn[:, i] ** 2 * test_xn[:, j]  # squared and linear interaction term\n","        k += 1\n","        X3[:, k] = test_xn[:, i] * test_xn[:, j] ** 2  # linear and squared interaction term\n","        k += 1\n","        for l in range(j + 1, n_features):\n","            X3[:, k] = test_xn[:, i] * test_xn[:, j] * test_xn[:, l]  # triple interaction term\n","            k += 1\n","\n","# Combine the original and new features\n","y_new = np.hstack((test_xn, X3))"],"metadata":{"id":"J3xnLu5d3g6S","executionInfo":{"status":"ok","timestamp":1677283389437,"user_tz":480,"elapsed":216,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["w = np.ones([13,1])\n","w_out = np.ones([13,10000])\n","\n","#Training \n","l = int(g.shape[0])\n","epochs = int(10000/l)\n","axis = []\n","\n","\n","\n","for i in range(epochs):\n","  count = 0\n","  xn,g,xn_label = shuffle(xn,g,xn_label)\n","  # g = shuffle(g)\n","  # xn_label = shuffle(xn_label)\n","\n","  for j in range(l):\n","    ind = i*epochs + j\n","    axis.append(ind + 1)\n","    z = np.dot(w.T, g[j,:])\n","\n","    if z <= 0:\n","      w = w + 1*g[j,:].reshape([13,1])\n","      count = 0\n","    \n","    else:\n","      count = count + 1\n","    \n","    w_out[:,ind] = w.T\n","  \n","  if count == 100:\n","    print('Linearly Separable')\n","    break\n","\n","J_d = np.zeros(10000)\n","\n","for j in range(10000):\n","  J_d[j] = crit(w_out[:,j], g)\n","\n","w_opt = w_out[:, np.argmin(J_d)]\n","print('The optimal weights are:', w_opt)\n","\n","train_label = predict(w_opt,xn)\n","print('The training classification error is:', error(train_label, xn_label))\n","\n","#test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","test_label = predict(w_opt,y_new)\n","\n","print('The testing classification error is:', error(test_label, y_label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6q0pcd924Ct5","executionInfo":{"status":"ok","timestamp":1677283395269,"user_tz":480,"elapsed":5096,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}},"outputId":"acbd19e5-8ed4-4cde-dc5b-2744ed049601"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Linearly Separable\n","The optimal weights are: [-4.         -1.56923092  4.12013992 -4.         -1.56923092  2.0025154\n","  1.19237056  4.12013992  3.91526967 -1.43627988 15.83841716  2.66454344\n","  3.81779624]\n","The training classification error is: 0.0\n","The testing classification error is: 4.0\n"]}]},{"cell_type":"code","source":["w = np.ones([13,1])\n","w_out = np.ones([13,10000])\n","\n","#Training \n","l = int(g.shape[0])\n","epochs = int(10000/l)\n","axis = []\n","accu_train = []\n","accu_test = []\n","k = 0\n","w_t = []\n","\n","while (k!=10):\n","  for i in range(epochs):\n","    count = 0\n","    xn,g,xn_label = shuffle(xn,g,xn_label)\n","    # g = shuffle(g)\n","    # xn_label = shuffle(xn_label)\n","\n","    for j in range(l):\n","      ind = i*epochs + j\n","      axis.append(ind + 1)\n","      z = np.dot(w.T, g[j,:])\n","\n","      if z <= 0:\n","        w = w + 1*g[j,:].reshape([13,1])\n","        count = 0\n","      \n","      else:\n","        count = count + 1\n","      \n","      w_out[:,ind] = w.T\n","    \n","    if count == 100:\n","      #print('Linearly Separable')\n","      break\n","\n","  J_d = np.zeros(10000)\n","\n","  for j in range(10000):\n","    J_d[j] = crit(w_out[:,j], g)\n","\n","  w_opt = w_out[:, np.argmin(J_d)]\n","  #print('The optimal weights are:', w_opt)\n","  w_t.append(w_opt)\n","\n","  train_label = predict(w_opt,xn)\n","  err = error(train_label, xn_label)\n","  accu_train.append(100 - err)\n","  #print('The training classification error is:', error(train_label, xn_label))\n","\n","  #test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","  test_label = predict(w_opt,y_new)\n","  err_test = error(test_label, y_label)\n","  accu_test.append(100 - err_test)\n","  k = k + 1\n","  #print('The testing classification error is:', error(test_label, y_label))\n","\n","mean_train = np.mean(np.array(accu_train), axis = 0)\n","std_train = np.std(np.array(accu_train), axis = 0)\n","mean_test = np.mean(np.array(accu_test), axis = 0)\n","std_test = np.std(np.array(accu_test), axis = 0)\n","\n","print(\"The mean and standard deviation for training accuracy is as follows: {:.2f}%, {:.2f}\".format(mean_train,std_train))\n","print(\"The mean and standard deviation for testing accuracy is as follows: {:.2f}%, {:.2f}\".format(mean_test,std_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOEqqVo_4XEd","executionInfo":{"status":"ok","timestamp":1677283450026,"user_tz":480,"elapsed":44971,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}},"outputId":"5f6fe4e8-8fb2-4511-8ac4-694bc2fb43a3"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["The mean and standard deviation for training accuracy is as follows: 100.00%, 0.00\n","The mean and standard deviation for testing accuracy is as follows: 96.00%, 0.00\n"]}]},{"cell_type":"code","source":["data_train = np.array(np.loadtxt(\"/content/dataset3_train.csv\", delimiter = \",\", dtype = float))\n","data_test = np.array(np.loadtxt(\"/content/dataset3_test.csv\", delimiter = \",\", dtype = float))\n","\n","xn_train,xn_label,xn_test,y_label = data_split(data_train, data_test)\n","\n","\n","xn1 = np.column_stack((np.ones([xn_train.shape[0],1],dtype=float),xn_train))\n","n_features = xn1.shape[1]\n","X3 = np.zeros((xn1.shape[0], n_features * (n_features + 1) * (n_features + 2) // 6))\n","k = 0\n","for i in range(n_features):\n","    X3[:, k] = xn1[:, i] ** 3  # cubic term\n","    k += 1\n","    for j in range(i + 1, n_features):\n","        X3[:, k] = xn1[:, i] ** 2 * xn1[:, j]  # squared and linear interaction term\n","        k += 1\n","        X3[:, k] = xn1[:, i] * xn1[:, j] ** 2  # linear and squared interaction term\n","        k += 1\n","        for l in range(j + 1, n_features):\n","            X3[:, k] = xn1[:, i] * xn1[:, j] * xn1[:, l]  # triple interaction term\n","            k += 1\n","\n","# Combine the original and new features\n","x_new = np.hstack((xn1, X3))\n","\n","xn, g = ref(x_new,xn_label)\n","\n","#Testing Dataset\n","test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","n_features = test_xn.shape[1]\n","X3 = np.zeros((test_xn.shape[0], n_features * (n_features + 1) * (n_features + 2) // 6))\n","k = 0\n","for i in range(n_features):\n","    X3[:, k] = test_xn[:, i] ** 3  # cubic term\n","    k += 1\n","    for j in range(i + 1, n_features):\n","        X3[:, k] = test_xn[:, i] ** 2 * test_xn[:, j]  # squared and linear interaction term\n","        k += 1\n","        X3[:, k] = test_xn[:, i] * test_xn[:, j] ** 2  # linear and squared interaction term\n","        k += 1\n","        for l in range(j + 1, n_features):\n","            X3[:, k] = test_xn[:, i] * test_xn[:, j] * test_xn[:, l]  # triple interaction term\n","            k += 1\n","\n","# Combine the original and new features\n","y_new = np.hstack((test_xn, X3))"],"metadata":{"id":"7tuC9T-A4at6","executionInfo":{"status":"ok","timestamp":1677283464022,"user_tz":480,"elapsed":193,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["w = np.ones([13,1])\n","w_out = np.ones([13,10000])\n","\n","#Training \n","l = int(g.shape[0])\n","epochs = int(10000/l)\n","axis = []\n","\n","\n","\n","for i in range(epochs):\n","  count = 0\n","  xn,g,xn_label = shuffle(xn,g,xn_label)\n","  # g = shuffle(g)\n","  # xn_label = shuffle(xn_label)\n","\n","  for j in range(l):\n","    ind = i*epochs + j\n","    axis.append(ind + 1)\n","    z = np.dot(w.T, g[j,:])\n","\n","    if z <= 0:\n","      w = w + 1*g[j,:].reshape([13,1])\n","      count = 0\n","    \n","    else:\n","      count = count + 1\n","    \n","    w_out[:,ind] = w.T\n","  \n","  if count == 100:\n","    print('Linearly Separable')\n","    break\n","\n","J_d = np.zeros(10000)\n","\n","for j in range(10000):\n","  J_d[j] = crit(w_out[:,j], g)\n","\n","w_opt = w_out[:, np.argmin(J_d)]\n","print('The optimal weights are:', w_opt)\n","\n","train_label = predict(w_opt,xn)\n","print('The training classification error is:', error(train_label, xn_label))\n","\n","#test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","test_label = predict(w_opt,y_new)\n","\n","print('The testing classification error is:', error(test_label, y_label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNplSFXh4joL","executionInfo":{"status":"ok","timestamp":1677283468717,"user_tz":480,"elapsed":3705,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}},"outputId":"ae7fa5de-a387-4fb9-878a-46fe7a1e8089"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["The optimal weights are: [ 13.         -36.30381659 -28.2672399   13.         -36.30381659\n","  75.98006214 -13.61373246 -28.2672399   21.51109684  -6.29694114\n","  -8.30207598  21.14363455   2.45840808]\n","The training classification error is: 6.0\n","The testing classification error is: 9.0\n"]}]},{"cell_type":"code","source":["w = np.ones([13,1])\n","w_out = np.ones([13,10000])\n","\n","#Training \n","l = int(g.shape[0])\n","epochs = int(10000/l)\n","axis = []\n","accu_train = []\n","accu_test = []\n","k = 0\n","w_t = []\n","\n","while (k!=10):\n","  for i in range(epochs):\n","    count = 0\n","    xn,g,xn_label = shuffle(xn,g,xn_label)\n","    # g = shuffle(g)\n","    # xn_label = shuffle(xn_label)\n","\n","    for j in range(l):\n","      ind = i*epochs + j\n","      axis.append(ind + 1)\n","      z = np.dot(w.T, g[j,:])\n","\n","      if z <= 0:\n","        w = w + 1*g[j,:].reshape([13,1])\n","        count = 0\n","      \n","      else:\n","        count = count + 1\n","      \n","      w_out[:,ind] = w.T\n","    \n","    if count == 100:\n","      #print('Linearly Separable')\n","      break\n","\n","  J_d = np.zeros(10000)\n","\n","  for j in range(10000):\n","    J_d[j] = crit(w_out[:,j], g)\n","\n","  w_opt = w_out[:, np.argmin(J_d)]\n","  #print('The optimal weights are:', w_opt)\n","  w_t.append(w_opt)\n","\n","  train_label = predict(w_opt,xn)\n","  err = error(train_label, xn_label)\n","  accu_train.append(100 - err)\n","  #print('The training classification error is:', error(train_label, xn_label))\n","\n","  #test_xn = np.column_stack((np.ones([xn_test.shape[0],1],dtype=float),xn_test))\n","  test_label = predict(w_opt,y_new)\n","  err_test = error(test_label, y_label)\n","  accu_test.append(100 - err_test)\n","  k = k + 1\n","  #print('The testing classification error is:', error(test_label, y_label))\n","\n","mean_train = np.mean(np.array(accu_train), axis = 0)\n","std_train = np.std(np.array(accu_train), axis = 0)\n","mean_test = np.mean(np.array(accu_test), axis = 0)\n","std_test = np.std(np.array(accu_test), axis = 0)\n","\n","print(\"The mean and standard deviation for training accuracy is as follows: {:.2f}%, {:.2f}\".format(mean_train,std_train))\n","print(\"The mean and standard deviation for testing accuracy is as follows: {:.2f}%, {:.2f}\".format(mean_test,std_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_pKNsWQ4mLq","executionInfo":{"status":"ok","timestamp":1677283598490,"user_tz":480,"elapsed":26927,"user":{"displayName":"Venkata Meghana Achanta","userId":"15385269140052891818"}},"outputId":"45453665-c219-4507-ab57-f83adbd2feba"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["The mean and standard deviation for training accuracy is as follows: 95.90%, 0.70\n","The mean and standard deviation for testing accuracy is as follows: 89.30%, 2.53\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VPo4zSdH5DUK"},"execution_count":null,"outputs":[]}]}